{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Logo.png\" width=\"100\" align=\"left\"/> \n",
    "\n",
    "# <center>Data Analytics project:</center>\n",
    "\n",
    "\n",
    "\n",
    "Congratulations on finishing the lessons content for this second unit !\n",
    "\n",
    "We have seen a lot of concepts in the second unit and we had the chance to test some of them. Now, we get to see how these different concepts are used to better understand our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some guidelines: \n",
    "1. To run a cell you can use the shortcut use : Shift + Enter\n",
    "\n",
    "2. Only sections mentioned as To-Do are the places where you should put in your own code other than that we do not recommend that you change the provided code.\n",
    "\n",
    "3. You will be graded for the visibility of your code so make sure you respect the correct indentation and that your code contains suitable variables names.\n",
    "\n",
    "4. This notebook is designed in a sequential way so if you solve your project on different days make sure to run the previous cells before you can run the one you want.\n",
    "\n",
    "5. Teacher assistants in the slack space remain available to answer any questions you might have.\n",
    "\n",
    ">Best of luck ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Sections:\n",
    "In this project you will practice some of the concepts seen in the data analytics unit, you will deal with a real dataset. This dataset contains house sale prices for King County. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "Our goal is to analyze this dataset, clean it then create a simple linear regression model using it.\n",
    "\n",
    "This project is devided into n sections : \n",
    "1. [Setting the environement](#set_env)\n",
    "\n",
    "2. [Importing necessary tools](#importing)\n",
    "\n",
    "3. [Dataset discovery](#dataset_discovery)\n",
    "\n",
    "4. [NA handling](#na_handling)\n",
    "\n",
    "5. [Useless variables deletion](#useless_var)\n",
    "\n",
    "6. [Outliers detection](#outliers)\n",
    "\n",
    "7. [Feature selection](#feature_selection)\n",
    "\n",
    "8. [Linear regression](#linear_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting the environement:  <a id='set_env'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: virtualenv in c:\\users\\hp\\anaconda3\\lib\\site-packages (20.10.0)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from virtualenv) (2.4.0)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from virtualenv) (1.16.0)\n",
      "Requirement already satisfied: backports.entry-points-selectable>=1.0.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from virtualenv) (1.1.1)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from virtualenv) (3.3.1)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from virtualenv) (0.3.4)\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have virtualenv installed \n",
    "!pip install --user virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: create a virtual environement called data_analytics\n",
    "!python -m venv data_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the environement for windows\n",
    "#!Source data_analytics/bin/activate\n",
    "!data_analytics\\Scripts\\activate.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex‚cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "# Activate the environement for linux (debian based)\n",
    "!. data_analytics/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing necessary tools:<a id='importing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataset discovery:<a id='dataset_discovery'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To-Do: Read the file (\"kc_house_data.csv\") using pandas and store in a dataframe called df\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "# To-Do: Print the dataframe's shape\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21606 non-null  object \n",
      " 2   price          21608 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21612 non-null  float64\n",
      " 6   sqft_lot       21612 non-null  float64\n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21609 non-null  float64\n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21611 non-null  float64\n",
      " 15  yr_renovated   21612 non-null  float64\n",
      " 16  zipcode        21611 non-null  float64\n",
      " 17  lat            21612 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21612 non-null  float64\n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(12), int64(8), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# To-Do: Print the dataframe's info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. NA handling:<a id='na_handling'></a>\n",
    "It is clear after printing the dataset info that there are some variables that have less entries than the number of rows which means that some of them don't have values in certain rows.\n",
    "\n",
    "Given the number of the na values, what do you think is the best method to deal with them?\n",
    "\n",
    "\n",
    "The best method to deal with them is Letwise Deletion, we delete rows that contain at least one missing value instead of creatin new db containing those changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: deal with the NAs in your dataset in one line\n",
    "df.dropna(inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Useless variables deletion:<a id='useless_var'></a>\n",
    "We want to eventually do a regression on it so naturally some variables bring no added value and can be delted without impacting the results.\n",
    "\n",
    "Delete the column that correspond to variables that aren't needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To-Do: delete the values of the variables that are useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A wild playground appears !!\n",
    "In the next cell, go wild with the dataset discovery.\n",
    "You can calculate the mean, the median or do anything you want to learn more the data.\n",
    "\n",
    "<b>Pro tip :</b> \n",
    "Sometimes you might want to know how many unique variables a column has, to do so you can use the padas function :\n",
    "\n",
    "<center>pd.unique(df['column_name'])</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : get to know more your data WITHOUT modifying it !!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Outliers detection:<a id='outliers'></a>\n",
    "Having outliers is a common problem that might affect the quality of the model that we're building.\n",
    "\n",
    "Let's assume that we're not interested in very expensive or very cheap houses, we want a model that best fits the average priced houses.\n",
    "\n",
    "To create such a model, we detect outliers and delete them using the Z-score method seen in the lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : detect the outliers then delete them ad delete the column created to calculate the Z-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Feature selection:<a id='feature_selection'></a>\n",
    "It is clear that even after deleting some features, there might be other features that aren't obviously useless but can be delted and keep a good overall performance.\n",
    "\n",
    "To verify this, we perform feature selection on our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : perform feature selection using correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do : drop the variables that seem highly correlated to you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Linear regression:<a id='linear_reg'></a>\n",
    "Now that our data is clean and ready to be used, let's try to fit it into a linear regression model.\n",
    "\n",
    "<ul>\n",
    "    <li>We begin by splitting our variables into dependant and independant variables.</li>\n",
    "    <li>We create the model using the LinearRegression class.</li>\n",
    "    <li>We evaluate our model using the R² score</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into dependant and independant variables\n",
    "Y = df['price']\n",
    "X = df.drop(['price'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# To-Do : Create a linear regression model using the LinearRegression class then fit it to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function used to calculate the R² score is the method \"score\" found in the LinearRegression class\n",
    "result.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "Data preparation is a very important step in the machine learning pipeline. It is crucial to clean our data and understand it very well before we can create any model on the data.\n",
    "\n",
    "In this notebook, we have spent 4 steps preparing our data but only 1 to create the model. This reflects how time consuming the process of data preparation is compared to the other steps as well as the importance of the quality of the data used.\n",
    "\n",
    "In the next unit, we will see more about the models creation process and see a lot of important concepts in depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
